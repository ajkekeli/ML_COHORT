{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b98dc590",
      "metadata": {
        "id": "b98dc590"
      },
      "source": [
        "\n",
        "# Part C: Model Building & Evaluation (Baseline Models)\n",
        "\n",
        "This section builds and evaluates baseline machine learning models for predicting loan default using the preprocessed dataset. We will use Logistic Regression and Decision Tree Classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab7b721",
      "metadata": {
        "id": "9ab7b721"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv(\"loan_data_preprocessed.csv\")  # Assumes file from previous steps\n",
        "X = df.drop(\"not.fully.paid\", axis=1)\n",
        "y = df[\"not.fully.paid\"]\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51457df1",
      "metadata": {
        "id": "51457df1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Logistic Regression\n",
        "log_model = LogisticRegression(max_iter=1000)\n",
        "log_model.fit(X_train, y_train)\n",
        "log_preds = log_model.predict(X_test)\n",
        "\n",
        "# Decision Tree\n",
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_preds = tree_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Measuring model Performance"
      ],
      "metadata": {
        "id": "9vfqAzo_M9C8"
      },
      "id": "9vfqAzo_M9C8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d3bdd6f",
      "metadata": {
        "id": "6d3bdd6f"
      },
      "outputs": [],
      "source": [
        "# Import tools to help us measure how well the model did\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt  # used for showing the chart\n",
        "import seaborn as sns  # makes our chart look nicer\n",
        "\n",
        "# Creating a simple function to check how good the model is\n",
        "def evaluate_model_simple(actual_labels, predicted_labels, model_name):\n",
        "    # Print the model name to know which one we're looking at\n",
        "    print(f\"\\nHow did {model_name} perform?\")\n",
        "\n",
        "    # Prints out the basic scores: Accuracy, Precision, Recall, F1\n",
        "    print(\"Here's the performance report:\")\n",
        "    print(classification_report(actual_labels, predicted_labels))\n",
        "\n",
        "    # Create the confusion matrix (it shows correct vs wrong predictions)\n",
        "    matrix = confusion_matrix(actual_labels, predicted_labels)\n",
        "\n",
        "    # Use seaborn to draw the matrix in a nice chart\n",
        "    sns.heatmap(matrix, annot=True, cmap=\"Blues\", fmt='d')  # fmt='d' makes numbers whole\n",
        "    plt.title(f\"{model_name} Confusion Matrix\")  # chart title\n",
        "    plt.xlabel(\"Predicted Labels\")  # x-axis: what the model guessed\n",
        "    plt.ylabel(\"Actual Labels\")     # y-axis: what it should have guessed\n",
        "    plt.show()  # show the chart\n",
        "\n",
        "# We test this function using the model predictions\n",
        "# log_preds = predictions from Logistic Regression\n",
        "# tree_preds = predictions from Decision Tree\n",
        "evaluate_model_simple(y_test, log_preds, \"Logistic Regression\")\n",
        "evaluate_model_simple(y_test, tree_preds, \"Decision Tree\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967932e0",
      "metadata": {
        "id": "967932e0"
      },
      "source": [
        "\n",
        "### Model Comparison\n",
        "\n",
        "Based on the evaluation metrics above, compare the Logistic Regression and Decision Tree performance. Consider F1 Score and Recall for unbalanced classes, and use these insights to select the better model for further improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### PART D:Advanced Models & Feature Importance\n",
        "\n"
      ],
      "metadata": {
        "id": "43PQ1lDeQziz"
      },
      "id": "43PQ1lDeQziz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "\n",
        "# Train a Gradient Boosting Classifier\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_preds = gb_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "_59TAetCQzHM"
      },
      "id": "_59TAetCQzHM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}